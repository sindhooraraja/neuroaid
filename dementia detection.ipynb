{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "711edc00",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cdba6da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_size = [224,224]\n",
    "data_path = 'Data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05e0f34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg = VGG16(input_shape= image_size+[3],weights='imagenet',include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9b8689d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<KerasTensor: shape=(None, 7, 7, 512) dtype=float32 (created by layer 'block5_pool')>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vgg.output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "461440d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = vgg.output\n",
    "x = GlobalAveragePooling2D()(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e2994df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Dense(1024,activation='relu')(x)\n",
    "x = Dense(1024,activation='relu')(x)\n",
    "x = Dense(512, activation='relu')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f016dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = Dense(2,activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbec20e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs = vgg.input,outputs=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c3f6735e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " global_average_pooling2d (G  (None, 512)              0         \n",
      " lobalAveragePooling2D)                                          \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1024)              525312    \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1024)              1049600   \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               524800    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 2)                 1026      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 16,815,426\n",
      "Trainable params: 16,815,426\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b95a59ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in vgg.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "045e48e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3329 images belonging to 2 classes.\n",
      "Found 819 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Directory paths for training and testing data\n",
    "train_data_dir = 'Data/train/'\n",
    "test_data_dir = 'Data/test/'\n",
    "\n",
    "# Image data generators for training and testing\n",
    "train_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "test_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "# Training data generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "# Testing data generator\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=(224, 224),\n",
    "    color_mode='rgb',\n",
    "    batch_size=32,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False  # Set shuffle to False for testing data\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "420e6fb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "104/104 [==============================] - 1200s 12s/step - loss: 0.9290 - accuracy: 0.7540 - val_loss: 0.4045 - val_accuracy: 0.7837\n",
      "Epoch 2/5\n",
      "104/104 [==============================] - 1374s 13s/step - loss: 0.3210 - accuracy: 0.8429 - val_loss: 0.5686 - val_accuracy: 0.7950\n",
      "Epoch 3/5\n",
      "104/104 [==============================] - 1565s 15s/step - loss: 0.2556 - accuracy: 0.8741 - val_loss: 0.9398 - val_accuracy: 0.8037\n",
      "Epoch 4/5\n",
      "104/104 [==============================] - 1215s 12s/step - loss: 0.2418 - accuracy: 0.8926 - val_loss: 0.4977 - val_accuracy: 0.8325\n",
      "Epoch 5/5\n",
      "104/104 [==============================] - 1123s 11s/step - loss: 0.1824 - accuracy: 0.9245 - val_loss: 0.8792 - val_accuracy: 0.8125\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Compile the model with an optimizer, loss function, and metrics\n",
    "model.compile(\n",
    "    optimizer=Adam(),\n",
    "    loss='categorical_crossentropy',  # Adjust the loss function based on your task\n",
    "    metrics=['accuracy']  # Adjust metrics based on your requirements\n",
    ")\n",
    "\n",
    "# Calculate steps per epoch for training data\n",
    "step_size_train = train_generator.n // train_generator.batch_size\n",
    "\n",
    "# Train the model using the training data generator\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=step_size_train,\n",
    "    epochs=5,\n",
    "    validation_data=test_generator,\n",
    "    validation_steps=test_generator.n // test_generator.batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "09215300",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "38adeca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('dementia.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
